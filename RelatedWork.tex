
The LDA model \cite{blei_latent_2003} has been extended in many different ways to address different problems. Information about document authorship has, for example, been added to the model in \cite{Rosen_Zvi_2004}, whereas the integration of correlations between topics in the model has been explored in \cite{blei_correlated_2007}; more recently, \cite{Boyd_Graber_2009} describes an extension to model multilingual unaligned collections. Other extensions have focused on streaming or online versions of the model: \cite{Yao_2009} focuses on efficient methods for inference in streaming collections, whereas \cite{Wang_2012} introduces a new model for text streams based on transition probabilities between topics of successive documents and \cite{hoffman_online_2010} proposes an online variational Bayes algorithm for LDA based on mini-batches.

Inference in LDA is usually performed through variational Bayes (as proposed in the original LDA paper \cite{blei_latent_2003}) or Gibbs sampling (as proposed in \cite{griffiths04finding}). Both methods have been extensively studied and collapsed versions, resulting in faster inference, have been proposed \cite{teh_collapsed_2006,porteous_fast_2008}. This last study, besides comparing the different approaches to inference in LDA, introduces gamma priors on the hyperparameters ($\alpha \sim G[a,b], \eta \sim G[c,d]$)\footnote{A similar prior is used in \cite{Gorur_2006} for Indian Buffet Processes.} which yield more stable models (in the sense that the difference between inference methods disappears when the priors are used). \cite{wallach_rethinking_2009} goes one step further by assessing the importance of priors on both the document-topic and word-topic distributions. The priors considered are asymmetric Dirichlet priors and the authors show that the use of such asymmetric priors has substantial advantages over the use of symetric priors, especially for the document-topic distrubition.

We follow here a similar approach but consider a true conjugate prior to the Dirichlet distribution which we call $\mbeta$. The use of a conjugate prior allows 
